{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.2 - Basic Convnet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNVu3Yjc87BTckzY66h7SYr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**First Example: MNIST Again**"],"metadata":{"id":"hkCNgo2ZeJKU"}},{"cell_type":"markdown","source":["Recall, the very first example we worked on was predicting digits from handwriting, using the MNIST dataset. Let's refresh on how that simple model performed. It was pretty impressive; it exceeds 98% accuracy. But, would you be comfortable deploying this at the USPS? \n","\n","What does a 2% error mean on this problem? It's worse than it appears. Think about the number of digits in a single address. There is a zip code, with 5 digits in it. If I make a mistake on any of the 5 digits, a sorting error will result. That means an error of 2% on a single prediction translates to a 10% error rate at the zipcode level (2+2+2+2+2). Even worse, addresses have house numbers in them (say there are 3 digits in the average house number, that means another 2+2+2, so our error rate is actually more like 16% at the address level. That's actually really bad! "],"metadata":{"id":"FZpairZReOL3"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","from tensorflow import keras \n","from tensorflow.keras import layers\n","\n","# Load the data.\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# Pre-process the data, to flatten the images into vectors and scale the values.\n","train_images = train_images.reshape((len(train_images), 28*28))\n","train_images = train_images.astype(\"float32\") / 255 \n","test_images = test_images.reshape((len(test_images), 28*28))\n","test_images = test_images.astype(\"float32\") / 255 \n","\n","# And reshape these to make sure the second dimension is formally defined as 1 (else you'll get a shape error in the model.fit() call)\n","train_labels = train_labels.reshape(len(train_labels),1)\n","test_labels = test_labels.reshape(len(test_labels),1)\n","\n","model = keras.Sequential([\n","    layers.Dense(512, activation=\"relu\"),\n","    layers.Dense(10, activation=\"softmax\")\n","])\n","\n","model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","history = model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2)"],"metadata":{"id":"TNbcbEsceUsi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So, we really need extremely high accuracy for this use case. Let's try a simple convnet, and see how it performs in comparison. It'll have a lot more parameters and take longer to train, of course, but the effort will be worth it. This model can get up to 99.5% error. Using similar logic to the above, this translates to an error rate of about 0.5*8 = 4% at the address level. Still not great, but it's much better."],"metadata":{"id":"uiwrGF-vhNoO"}},{"cell_type":"markdown","source":["# **Now Let's Try a ConvNet**"],"metadata":{"id":"5ZyNm6-HTrdl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXvJCzZ4czC_"},"outputs":[],"source":["from tensorflow.keras.datasets import mnist\n","from tensorflow import keras \n","from tensorflow.keras import layers\n","\n","# Load the data.\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# Pre-process the data - notice we are not flattening the images into vectors anymore! We are keeping them in a higher-rank tensor format. \n","# This is important, because the Conv2D layer is designed specifically for image data! It's going to scan over subsets of the image to identify features.\n","# The format here thus translates to: (observations,image_width,image_height,color_channels).\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype(\"float32\") / 255 \n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype(\"float32\") / 255 \n","train_labels = train_labels.reshape(len(train_labels),1)\n","test_labels = test_labels.reshape(len(test_labels),1)\n","\n","print(train_images.shape)\n","\n","# Define the Convnet\n","inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","# Compile the network model.\n","model.compile(optimizer=\"rmsprop\",\n","              loss=\"sparse_categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","keras.utils.plot_model(model, show_shapes=True)\n","model.summary()\n"]},{"cell_type":"code","source":["# Fit the model. \n","history = model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"id":"lBf939q_vnti"},"execution_count":null,"outputs":[]}]}