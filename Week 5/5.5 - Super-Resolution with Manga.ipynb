{"cells":[{"cell_type":"markdown","metadata":{"id":"FaU3Io_f2qHr"},"source":["##**Image-Sharpening ConvNet**"]},{"cell_type":"markdown","metadata":{"id":"kRhYoTBn2ucZ"},"source":["We are going to work with high-res images of a bunch of manga comicbook covers. Word of warning: high-res images means tons of pixels, which means tons of data in memory and big tensor operations. "]},{"cell_type":"markdown","metadata":{"id":"uR5S8SzvcRM4"},"source":["# Import Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1308,"status":"ok","timestamp":1644777513257,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"},"user_tz":300},"id":"ITse3wTNcTEP","outputId":"cfce5669-b33c-4ad3-f04a-625035dadeb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","from google.colab import files\n","import io\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORkRjUeRfLvX"},"outputs":[],"source":["import numpy as np\n","import glob\n","from PIL import Image, ImageDraw\n","import matplotlib.pyplot as plt\n","\n","image_list = []\n","for file in glob.glob(\"/content/drive/My Drive/Teaching/Courses/BA 865/BA865-2022/Week 5/datasets/manga_low/*\"):\n","    im=Image.open(file)\n","    # I am stripping off the last row.\n","    img_array = np.array(im)[:-1,:,:]\n","    # Then I am adding two columns of white pixels. Why\n","    white = np.ones(shape=(584,2,3))*255\n","    img_array = np.hstack([img_array,white])  \n","    img_array = np.divide(img_array,255)\n","    image_list.append(img_array)\n","\n","dpi = 80\n","  \n","height, width, depth = image_list[0].shape\n","figsize = width / float(dpi), height / float(dpi)\n","\n","print(f'The shape if each image is {image_list[0].shape}.')\n","\n","plt.figure(figsize=figsize)\n","plt.imshow(image_list[0])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KIOKEEdx_b64"},"source":["#*Optional: Dataset Augmentation.*"]},{"cell_type":"markdown","source":["With image data, it's pretty straight forward for us to synthesize new training examples by copying and then randomly manipulating the images we've already got!"],"metadata":{"id":"Zug6bF5NAYhm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZjENtVV_2j6"},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator\n","import tensorflow as tf\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=40,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","\n","# First, 'train' the image data generator on our sample.\n","datagen.fit(image_list)\n","\n","# Now we create the iterator... we can keep pulling new randomly transformed pictures out of this forever. \n","image_batches = datagen.flow(np.stack(image_list,axis=0), batch_size=30)\n","\n","n = 5\n","plt.figure(figsize= (20,10))\n","\n","q = 0\n","for i,batch in enumerate(image_batches):\n","    for j, image in enumerate(batch): \n","        if j == 1: \n","            # Only plot the first 6 photos.\n","            if i <= 5:\n","                ax = plt.subplot(1, 6, i+1)\n","                plt.imshow(tf.keras.utils.array_to_img(image))\n","                ax.get_xaxis().set_visible(False)\n","                ax.get_yaxis().set_visible(False)\n","        \n","        # The iterator outputs image data with pixel values between 0-1; we are using values between 0-255 elsewhere.\n","        # We need to make the pixel values align.\n","        image_list.append(np.multiply(image,255))\n","\n","    # Telling the script to stop asking for new images after several batches.\n","    if q > 5:\n","      break\n","\n","    q += 1    \n","\n","plt.show()\n","\n","print(f'We now have a total of {len(image_list)} images.')"]},{"cell_type":"markdown","metadata":{"id":"4_6zWxkGkOn3"},"source":["Lastly, let's make our X's now; the pixellated versions of the high resolution images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6LobkiTlgMX"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","image_L_list = []\n","pixelated_list = []\n","pixelated_L_list = []\n","\n","# This part determines how difficult the problem is.\n","# If we downsample too much, there's not enough signal left in the data to recover the original.\n","# Try this with downsampling to 100x100 or even lower. The model won't be able to solve the problem.\n","for image in image_list:\n","  image = Image.fromarray(np.multiply(image,255).astype('uint8'))\n","  \n","  # First, get the Luminance value from the original RBG image (the Y in the three YCrCb signals.)\n","  image_L = image.convert('L')\n","  image_L = tf.keras.utils.img_to_array(image_L)\n","  image_L_list.append(image_L)\n","    \n","  # Next, make the pixelated version of the original image.\n","  image_tiny = image.resize((100,100))    # resize it to a tiny size\n","  pixelated = image_tiny.resize(image.size,Image.NEAREST)   # scale it back up\n","  pixelated_L = pixelated.convert('L')\n","  \n","  pixelated_RGB = pixelated_L.convert('RGB')\n","  \n","  # Store the pixelated photo.\n","  pixelated = tf.keras.utils.img_to_array(pixelated)\n","  pixelated_list.append(pixelated)\n","  \n","  # Then, store the luminence value of the pixelated photo (we will pull out the CbCr channels later and upscale them to create final output photos)\n","  pixelated_L = tf.keras.utils.img_to_array(pixelated_L)\n","  pixelated_L_list.append(pixelated_L)\n","\n","# We will put these into NumPy arrays for use in our NN later.\n","pixelated_array = np.stack(pixelated_list, axis=0)\n","pixelated_L_array = np.stack(pixelated_L_list, axis=0)\n","image_L_array = np.stack(image_L_list, axis=0)\n","image_array = np.stack(image_list, axis=0)\n","\n","# Let's plot the first 5 pairs of training images and their labels (in RGB).\n","n = 5\n","plt.figure(figsize= (20,10))\n","\n","for i in range(n):\n","  ax = plt.subplot(2, n, i+1)\n","  plt.imshow(tf.keras.utils.array_to_img(pixelated_list[i]))\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","  \n","  ax = plt.subplot(2, n, i+1+n)\n","  plt.imshow(tf.keras.utils.array_to_img(image_list[i]))\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OEBkFIw4-92J"},"source":["# Create Our Neural Network"]},{"cell_type":"markdown","metadata":{"id":"hc1fWGWK_DKm"},"source":["Now, we just need to create a model that takes the pixelated image as input, and tries to predict the original. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6thSmWpU_IaU"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import math\n","from keras import backend as K\n","\n","# These are both custom loss functions we can define that are appropriate for measuring differences between to pictures.\n","def psnrLoss(y_true, y_pred, max_pixel=255.0):\n","    psnr = tf.image.psnr(y_true,y_pred,max_val=max_pixel)\n","    return psnr\n","\n","def ssim_msLoss(y_true, y_pred,max_val=255.0):\n","    ssim = tf.image.ssim_multiscale(y_true,y_pred,max_val)\n","    return ssim\n","\n","conv_args = {\n","        \"activation\": \"relu\",\n","        \"kernel_initializer\": \"Orthogonal\",\n","        \"padding\": \"same\"\n","    }\n","\n","from tensorflow import keras \n","from tensorflow.keras import layers\n","  \n","inputs = keras.Input(shape=(height, width, 1))\n","x = layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\")(inputs)\n","x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\")(x)\n","x = layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\")(x)\n","\n","x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n","x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n","x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\")(x)\n","x = layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n","outputs = layers.Conv2D(1, 3, activation=\"linear\", padding=\"same\")(x)\n"," \n","model = keras.Model(inputs, outputs)\n","model.summary()\n","\n","# Compile the model - note, PSNR is positive signal to noise ratio (a loss metric that is specific to assessing image quality)\n","model.compile(optimizer=\"adam\", loss='mse', metrics=[psnrLoss])"]},{"cell_type":"markdown","metadata":{"id":"yzePRThQeKfC"},"source":["Okay, let's try fitting this model... "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQD-IP0ceMtW"},"outputs":[],"source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"superResolution.keras\",\n","                                    save_best_only=True)\n","]\n","\n","history = model.fit(pixelated_L_array,image_L_array,batch_size=1,epochs=50, validation_split=0.2,callbacks=callbacks)"]},{"cell_type":"markdown","metadata":{"id":"IqF8EJDYeN0B"},"source":["And, let's plot the loss over epochs... "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h546pKq1eP9u"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['val_psnrLoss'][10:],c=\"b\")\n","plt.plot(history.history['psnrLoss'][10:],c=\"r\")\n","plt.legend(['Validation','Training'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1-aRVIgYeecw"},"source":["Let's spit out some of the predictions from this model to see how well it works..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMXT6vfKeiMt"},"outputs":[],"source":["## This can be done mouch more cleanly. Write a function to take an RGB image, parse out Y, Cr, Cb. \n","def predict_to_RGB(pixelated_array,pixelated_L_array):\n","\n","  # First, get the predicted luminosity signal based on each pixelated photo's luminosity signal.\n","  predicted_L_array = model.predict(pixelated_L_array)\n","  \n","  result = []\n","  for i in range(pixelated_array.shape[0]):\n","      \n","      # Next, for each pixelated photo, strip out its Cb and Cr signals for reuse in the final sharpened photo.\n","      ycbcr = tf.keras.utils.array_to_img(pixelated_array[i]).convert(\"YCbCr\")\n","      L, cb, cr = ycbcr.split()\n","\n","      # Convert the predicted L signal from numpy array format into a PIL Image. \n","      predicted_L = Image.fromarray(np.uint8(predicted_L_array[i][:,:,0]), mode=\"L\")\n","\n","      # Combine the PIL luminosity Image with the PIL Cb and Cr images, and convert the result back into RBG format for display. \n","      result.append(Image.merge(\"YCbCr\", (predicted_L, cb, cr)).convert(\"RGB\"))\n","  \n","  return np.stack(result,axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjmdbSJglSkk"},"outputs":[],"source":["sharpened_array = predict_to_RGB(pixelated_array[:15], pixelated_L_array[:15])"]},{"cell_type":"markdown","source":["Our sharpener works, though it has some trouble with white pixels (it fills in some black pixels). It may need more white examples to figure those out well. "],"metadata":{"id":"mjxm5zONFeEC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG_RvGgQez9v"},"outputs":[],"source":["n = 5\n","plt.figure(figsize= (20,10))\n","\n","for i in range(n):\n","  ax = plt.subplot(2, n, i+1)\n","  plt.imshow((pixelated_array[i]).astype('uint8'))\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","\n","  ax = plt.subplot(2, n, i+1+n)\n","  plt.imshow((sharpened_array[i]).astype('uint8'))\n","  ax.get_xaxis().set_visible(False)\n","  ax.get_yaxis().set_visible(False)\n","\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"name":"5.4 - Super-Resolution with Manga.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}