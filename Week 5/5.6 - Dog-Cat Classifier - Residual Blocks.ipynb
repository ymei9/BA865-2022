{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.3-b - Dog-Cat Classifier - Residual Blocks.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP9pz0VJUi4Ot4lZc/ZU1Xy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import Our Data"],"metadata":{"id":"eCSoCdiypuds"}},{"cell_type":"markdown","source":["Save the data to your Google Drive. Then you can mount your drive and access the folder from wherever you saved it."],"metadata":{"id":"qqE8qCGJ7l_o"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"O8mX6tcsZQTB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644779864502,"user_tz":300,"elapsed":15059,"user":{"displayName":"Gordon Burtch","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6kdrNKuddVmCp6HcajLgk8KM0o5MC7oJKYfMbVGU=s64","userId":"10144756805379529333"}},"outputId":"536cbbf1-9fdf-4165-af2e-17270df9d678"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Here, we are using the image_dataset_from_directory utilty, which reads images from a file path into a tf.Dataset object. This is much more memory efficient than reading images into lists! The dataset is already organized into training, test, and validation splits on my file system. The labels are inferred from the folder names. "],"metadata":{"id":"MCBGFPh6pwoR"}},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","base_dir = \"drive/My Drive/Teaching/Courses/BA 865/BA865-2022/Week 5/datasets/dogs-vs-cats\"\n","  \n","train_dataset = image_dataset_from_directory(\n","    base_dir + \"/train/\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    base_dir + \"/validation/\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    base_dir + \"/test/\",\n","    image_size=(180, 180),\n","    batch_size=32)"],"metadata":{"id":"IxKRDWD6nNZi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for data_batch, labels_batch in train_dataset:\n","     print(\"data batch shape:\", data_batch.shape)\n","     print(\"labels batch shape:\", labels_batch.shape)\n","     break"],"metadata":{"id":"KF9xMKHwpejj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Our Model"],"metadata":{"id":"IdW__Gp7prDy"}},{"cell_type":"code","source":["from tensorflow import keras \n","from tensorflow.keras import layers\n","\n","data_augmentation = keras.Sequential([\n","   layers.RandomFlip(\"horizontal\"),\n","   layers.RandomRotation(0.1),\n","   layers.RandomZoom(0.2),\n","])\n","\n","inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = layers.Rescaling(1./255)(inputs)\n","x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n"," \n","for size in [32, 64, 128]:\n","    residual = x\n"," \n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","    x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n","  \n","    x = layers.BatchNormalization()(x)\n","    x = layers.Activation(\"relu\")(x)\n","    x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n","  \n","    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n","  \n","    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n","    x = layers.add([x, residual])\n","  \n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","keras.utils.plot_model(model,show_shapes=True)"],"metadata":{"id":"QnI5kP0dpqA1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We have a binary outcome variable, hence our use of Sigmoid activation on the output layer. We will use binary cross-entropy loss as our loss function. And, we'll monitor accuracy."],"metadata":{"id":"4rvfZ5gWrHkd"}},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"kODtn507qqV2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This callback we are defining will write the current best model (and parameter values) to disk, based on minimum validation loss. "],"metadata":{"id":"QR058X8Nq5-3"}},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"Xception.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]"],"metadata":{"id":"b_LWImEPq5M1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that batch size isn't defined here, because we defined it when we first created the tf.Dataset object! This Dataset object is an iterator, containing batches of images."],"metadata":{"id":"G6vrirzrrWTk"}},{"cell_type":"code","source":["history = model.fit(\n","    train_dataset,\n","    epochs=100,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"dUQciZrQrC_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["And we can plot loss over training iterations..."],"metadata":{"id":"zfASbQht93rn"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['val_accuracy'],c=\"b\")\n","plt.plot(history.history['accuracy'],c=\"r\")\n","plt.legend(['Validation Acc','Training Acc'])\n","plt.show()"],"metadata":{"id":"eLs620wf96hj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that we can now reach ~70% accuracy with 100 epochs of learning... "],"metadata":{"id":"nTAotbse9ctY"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\"Xception.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset) \n","print(f\"Test accuracy: {test_acc}\")"],"metadata":{"id":"X_ue1fK06xK2"},"execution_count":null,"outputs":[]}]}